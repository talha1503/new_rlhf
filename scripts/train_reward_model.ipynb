{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ea4455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f394859c-15e5-490d-a9b0-3221ad3b164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb054e5-d482-43f7-b09e-d80c5914b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\eleutherai\\rlhf_fairness\\rlhf-fairness\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from source.evaluate_models import evaluate_model\n",
    "from source.losses import preference_loss_function\n",
    "from source.mlp import MLP\n",
    "from source.training import train_reward_model, get_norm_dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b47185-8df0-4a95-8af6-7a5360a1ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_action_features = ['default_rate-group_1', 'default_rate-group_2', \n",
    "#                          'acceptance_rate-group_1', 'acceptance_rate-group_2', \n",
    "#                          'average_credit_score-group_2', 'average_credit_score-group_1',\n",
    "#                          'applicant_credit_group', 'applicant_group_membership', 'agent_action']\n",
    "\n",
    "reward_model_features = ['default_rate-group_1', 'default_rate-group_2', \n",
    "                         'acceptance_rate-group_1', 'acceptance_rate-group_2', \n",
    "                         'average_credit_score-group_2', 'average_credit_score-group_1',\n",
    "                         'applicant_credit_group', 'applicant_group_membership', 'agent_action'\n",
    "                        ]\n",
    "# reward_model_features = ['applicant_credit_group', 'agent_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b127c1-12f7-440c-a861-37d28093e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sample_trajectory_df(input_df, n_sample_points = 20):\n",
    "    trajectory_df = input_df.copy()\n",
    "    if len(trajectory_df)//2 > n_sample_points:\n",
    "        sample_step_size = len(trajectory_df) // n_sample_points\n",
    "        trajectory_df = trajectory_df.reset_index(drop=True)\n",
    "        sample_index = [i for i in range(len(trajectory_df)) if i%sample_step_size == 0]\n",
    "        trajectory_df_sampled = trajectory_df[trajectory_df.index.isin(sample_index)]\n",
    "        return trajectory_df_sampled\n",
    "    else:\n",
    "        return trajectory_df\n",
    "    \n",
    "def sample_trajectory_features(input_df, base_features, n_sample_points = 20):\n",
    "    window_size = len(input_df)//n_sample_points\n",
    "    features = {\"min\": input_df[base_features].min().to_dict(),\n",
    "                \"max\": input_df[base_features].max().to_dict(),\n",
    "                \"mean\": input_df[base_features].mean().to_dict(),\n",
    "                \"std\": input_df[base_features].std().to_dict()\n",
    "               }\n",
    "    tmp_features_ma = input_df[base_features].rolling(window=window_size//2).mean().dropna(subset=base_features)\n",
    "    tmp_features_ma_sampled = sample_trajectory_uniform(tmp_features_ma, n_sample_points=n_sample_points)\n",
    "    \n",
    "    features_df_ma_vals = []\n",
    "    features_df_ma_names = []\n",
    "    tmp_input_df = tmp_features_ma_sampled.reset_index(drop=True)\n",
    "    original_cols = tmp_input_df.columns\n",
    "    for idx, row in tmp_input_df.iterrows():\n",
    "        features_df_ma_vals += list(row.values)\n",
    "        features_df_ma_names += [f\"{i}_{idx}\" for i in original_cols]\n",
    "\n",
    "    features_df_ma = pd.DataFrame(features_df_ma_vals, index=features_df_ma_names).T\n",
    "    \n",
    "    feature_df = []\n",
    "    for k, v in features.items():\n",
    "        tmp_df = pd.DataFrame.from_dict(v, orient=\"index\").T\n",
    "        tmp_df.columns = [f\"{i}_{k}\" for i in tmp_df.columns]\n",
    "        feature_df.append(tmp_df)\n",
    "\n",
    "    feature_df = pd.concat(feature_df + [features_df_ma], axis=1)\n",
    "    return feature_df\n",
    "\n",
    "def get_accuracy_result(metrics_report_history):\n",
    "    acc_list = []\n",
    "    for k, v in metrics_report_history.items():\n",
    "        acc_list.append(v['accuracy'])\n",
    "    \n",
    "    print(\"Accuracy history: \", acc_list)\n",
    "    print(\"Mean (5-fold): \", np.array(acc_list).mean())\n",
    "    print(\"Std (5-fold): \", np.array(acc_list).std())\n",
    "    return acc_list\n",
    "\n",
    "def convert_filenames_to_trajectories(df,\n",
    "                                      state_action_features,\n",
    "                                      target,\n",
    "                                      trajecotry_folder=\"../data/trajectories\", \n",
    "                                      n_sample_points=20,\n",
    "                                      n_sample=-1\n",
    "                                     ):\n",
    "    res_df = pd.DataFrame()\n",
    "    modelling_df = df.copy().head(n_sample)\n",
    "    for idx, row in modelling_df.iterrows():\n",
    "        option_a_file = row['Trajectory_A']\n",
    "        option_b_file = row['Trajectory_B']\n",
    "        tmp_df_a = pd.read_csv(f\"{trajecotry_folder}/{option_a_file}\", index_col=[0])\n",
    "        tmp_df_b = pd.read_csv(f\"{trajecotry_folder}/{option_b_file}\", index_col=[0])\n",
    "\n",
    "#         tmp_df_a_sampled = n_sample_trajectory_df(tmp_df_a, n_sample_points=n_sample_points)\n",
    "#         tmp_df_b_sampled = n_sample_trajectory_df(tmp_df_b, n_sample_points=n_sample_points)  \n",
    "        tmp_df_a_sampled = sample_trajectory_features(tmp_df_a, state_action_features, n_sample_points=n_sample_points)\n",
    "        tmp_df_b_sampled = sample_trajectory_features(tmp_df_b, state_action_features, n_sample_points=n_sample_points)  \n",
    "        \n",
    "        tmp_df_a_sampled = tmp_df_a_sampled[state_action_features]\n",
    "        tmp_df_b_sampled = tmp_df_b_sampled[state_action_features]\n",
    "\n",
    "        tmp_df_a_sampled.columns = [f\"{i}_a\" for i in tmp_df_a_sampled.columns]\n",
    "        tmp_df_b_sampled.columns = [f\"{i}_b\" for i in tmp_df_b_sampled.columns]\n",
    "        tmp_df = pd.concat([tmp_df_a_sampled, tmp_df_b_sampled], axis=1)\n",
    "        tmp_df[target] = 0 if row[target] == 'a' else 1        \n",
    "        res_df = res_df.append(tmp_df)\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2181ff-a1ec-419f-a233-97a64737f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"\n",
    "decision_col = 'Decision_fair'\n",
    "\n",
    "save_dir = \"./\"\n",
    "reward_model_name = \"fair_gpt_reward_model\"\n",
    "synthetic_preferences_path = \"D:\\\\Work\\\\EleutherAI\\\\fairness_gym\\\\ml-fairness-gym\\\\fixed_gpt_preferences_formatted_all.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80135648-2595-4e87-b3a8-60ef7c9ba91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b    3216\n",
      "a    1588\n",
      "Name: Decision_fair, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "preferences_df = pd.read_csv(synthetic_preferences_path)\n",
    "\n",
    "preferences_df_filtered = preferences_df[['Trajectory_A', 'Trajectory_B', decision_col]]\n",
    "preferences_df_filtered = preferences_df_filtered.dropna(subset=[decision_col])\n",
    "preferences_df_filtered = preferences_df_filtered[preferences_df_filtered[decision_col].isin(['a', 'b'])]\n",
    "print(preferences_df_filtered[decision_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36bbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate rows for values 'a' and 'b'\n",
    "df_a = preferences_df_filtered[preferences_df_filtered[decision_col] == 'a']\n",
    "df_b = preferences_df_filtered[preferences_df_filtered[decision_col] == 'b']\n",
    "\n",
    "# Determine the minimum count of rows\n",
    "min_count = min(len(df_a), len(df_b))\n",
    "\n",
    "# Sample equal number of rows for 'a' and 'b'\n",
    "df_a = df_a.sample(n=min_count, random_state=42)\n",
    "df_b = df_b.sample(n=min_count, random_state=42)\n",
    "\n",
    "# Concatenate the sampled DataFrames\n",
    "filtered_df = pd.concat([df_a, df_b])\n",
    "\n",
    "# Reset the index of the filtered DataFrame\n",
    "filtered_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ec8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fadb24-b313-41d3-a3a3-ab72263234c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(99)\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "        self.y = torch.tensor(dataframe[target].values).float()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        y = self.y[i].to(self.device)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada9130a-de22-420b-8a8f-51a884b60587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################\n",
    "### The model and learning algorithm ##\n",
    "#######################################\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units, num_layers=1, out_features=1, name=\"reward_model\"):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.name = name\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "def train_model(data_loader, model, loss_function, optimizer, return_loss=False, verbose=False):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / (num_batches+1*10**-9)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Train loss: {avg_loss}\")\n",
    "    \n",
    "    if return_loss:\n",
    "        return avg_loss\n",
    "\n",
    "def test_model(data_loader, model, loss_function, return_loss=False, verbose=False):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / (num_batches + 1*10**-9)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Test loss: {avg_loss}\")\n",
    "    \n",
    "    if return_loss:\n",
    "        return avg_loss\n",
    "    \n",
    "def predict(data_loader, model):\n",
    "\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_trajectories_comparison_df(df,\n",
    "                                  state_action_features,\n",
    "                                  target,\n",
    "                                  trajecotry_folder=\"../data/trajectories\", \n",
    "                                  n_sample_points=20\n",
    "                                 ):\n",
    "    res_df = pd.DataFrame()\n",
    "    modelling_df = df.copy()\n",
    "    for idx, row in modelling_df.iterrows():\n",
    "        option_a_file = row['Trajectory_A']\n",
    "        option_b_file = row['Trajectory_B']\n",
    "        tmp_df_a = pd.read_csv(f\"{trajecotry_folder}/{option_a_file}\", index_col=[0])\n",
    "        tmp_df_b = pd.read_csv(f\"{trajecotry_folder}/{option_b_file}\", index_col=[0])\n",
    "\n",
    "        tmp_df_a_sampled = n_sample_trajectory_df(tmp_df_a, n_sample_points=n_sample_points)\n",
    "        tmp_df_b_sampled = n_sample_trajectory_df(tmp_df_b, n_sample_points=n_sample_points)    \n",
    "        tmp_df_a_sampled = tmp_df_a_sampled[state_action_features]\n",
    "        tmp_df_b_sampled = tmp_df_b_sampled[state_action_features]\n",
    "\n",
    "        tmp_df_a_sampled.columns = [f\"{i}_a\" for i in tmp_df_a_sampled.columns]\n",
    "        tmp_df_b_sampled.columns = [f\"{i}_b\" for i in tmp_df_b_sampled.columns]\n",
    "        tmp_df = pd.concat([tmp_df_a_sampled, tmp_df_b_sampled], axis=1)\n",
    "\n",
    "        tmp_df[target] = 0 if row[target] == 'a' else 1  \n",
    "        res_df = res_df.append(tmp_df)\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "    return res_df\n",
    "    \n",
    "def get_dataloader(df_train, df_test, features, target, sequence_length, batch_size, torch_seed=101):\n",
    "    # Create dataloader objects\n",
    "    torch.manual_seed(torch_seed)\n",
    "#     tmp_df_train, tmp_df_test = normalize_train_test(df_train, df_test)\n",
    "    train_dataset = SequenceDataset(df_train, target=target, features=features, sequence_length=sequence_length)\n",
    "    test_dataset = SequenceDataset(df_test, target=target, features=features, sequence_length=sequence_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfc1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1d755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectories generated: \n"
     ]
    }
   ],
   "source": [
    "n_sample_points = 20\n",
    "X = filtered_df.drop([decision_col], axis=1)\n",
    "y = filtered_df[decision_col]\n",
    "\n",
    "report_history = {}\n",
    "cm_history = {}\n",
    "# Training the model and evaluate with k-fold\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "train_df = pd.concat([X_tr, y_tr], axis=1)\n",
    "test_df = pd.concat([X_te, y_te], axis=1)\n",
    "# Attach the trajectories to the file names\n",
    "train_trajectories = get_trajectories_comparison_df(train_df,\n",
    "                              reward_model_features,\n",
    "                              target=decision_col,\n",
    "                              trajecotry_folder=\"../data/trajectories\", \n",
    "                              n_sample_points=n_sample_points\n",
    "                             )\n",
    "test_trajectories = get_trajectories_comparison_df(test_df,\n",
    "                              reward_model_features,\n",
    "                              target=decision_col,\n",
    "                              trajecotry_folder=\"../data/trajectories\", \n",
    "                              n_sample_points=n_sample_points\n",
    "                             )\n",
    "# for i in range(1):\n",
    "    # Split the file names into training and testing sets\n",
    "    \n",
    "print(\"Trajectories generated: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810b3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preference_loss_function_3(sum_a, sum_b, decisions):\n",
    "    '''\n",
    "    sum_a -> batch_size, 1\n",
    "    sum_b -> batch_size, 1\n",
    "    '''\n",
    "    sum_a = sum_a.unsqueeze(1)\n",
    "    sum_b = sum_b.unsqueeze(1)\n",
    "    stacked_tensor = torch.cat([sum_a, sum_b], dim=1)\n",
    "    stacked_tensor = stacked_tensor.to(torch.float32)\n",
    "    decisions = decisions.to(torch.float32)\n",
    "    loss = F.cross_entropy(stacked_tensor, decisions)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4434c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7755, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sum_a = torch.rand(20).to(torch.device('cuda'))\n",
    "sum_b = torch.rand(20).to(torch.device('cuda'))\n",
    "decisions = torch.rand(20,2).to(torch.device('cuda'))\n",
    "l = preference_loss_function_3(sum_a, sum_b, decisions)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c21d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from source.datasets import TabularDataset\n",
    "def train_reward_model(model,\n",
    "                       input_dim,\n",
    "                       train_loader,\n",
    "                       loss_function,\n",
    "                       learning_rate,\n",
    "                       num_epochs,\n",
    "                       batch_size,\n",
    "                       save_dir,\n",
    "                       ):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(\"Training with: {}\".format(device))\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = [-np.inf]\n",
    "    for epoch in range(num_epochs):\n",
    "        tmp_losses = []\n",
    "        reward_A_list = []\n",
    "        reward_B_list = []\n",
    "        accuracy_list = []\n",
    "        # with train_loader as batches:\n",
    "        # batches.set_description(f\"Training - Epoch {epoch + 1} - Loss {round(losses[-1], 4)}\")\n",
    "        for features, decisions in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            features = features.to(device)\n",
    "            feature_last_dim = features.size(2)\n",
    "            curr_batch_size = features.size(0)\n",
    "            features_a = features[:, :input_dim, :]\n",
    "            features_a = features_a.transpose(1, 2)\n",
    "            features_a = features_a.contiguous().view(-1, input_dim).to(device)\n",
    "            \n",
    "            features_b = features[:, input_dim:, :]\n",
    "            features_b = features_b.transpose(1, 2)\n",
    "            features_b = features_b.contiguous().view(-1, input_dim).to(device)\n",
    "            \n",
    "            reward_A = model(features_a)\n",
    "            reward_B = model(features_b)\n",
    "            \n",
    "            reward_A = torch.sum(reward_A.view(curr_batch_size, -1), 1)\n",
    "            reward_B = torch.sum(reward_B.view(curr_batch_size, -1), 1)\n",
    "            decisions = F.one_hot(decisions.to(torch.int64), num_classes=2)\n",
    "            loss = loss_function(reward_A, reward_B, decisions)\n",
    "            \n",
    "            reward_A = reward_A.unsqueeze(1)\n",
    "            reward_B = reward_B.unsqueeze(1)\n",
    "            stacked_tensor = torch.cat([reward_A, reward_B], dim=1)\n",
    "            stacked_tensor = stacked_tensor.to(torch.float32)\n",
    "            curr_accuracy = get_accuracy(stacked_tensor, decisions)\n",
    "            accuracy_list.append(curr_accuracy.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tmp_losses.append(loss.item())\n",
    "        \n",
    "        acc = sum(accuracy_list) / len(accuracy_list)\n",
    "        print(\"ON EPOCH {} Training Accuracy: {}: \".format(epoch, acc))    \n",
    "        losses.append(np.mean(tmp_losses))\n",
    "            # batches.set_postfix({\"loss\": np.mean(losses)})\n",
    "\n",
    "    torch.save(model, os.path.join(save_dir, model.name + \".pt\"))\n",
    "    return losses, model\n",
    "\n",
    "def get_norm_dict(df_train, target):\n",
    "    mean_dict = {}\n",
    "    stdev_dict = {}\n",
    "    for c in df_train.columns:\n",
    "        if c != target:\n",
    "            mean_dict[c] = df_train[c].mean()\n",
    "            stdev_dict[c] = df_train[c].std()\n",
    "    return mean_dict, stdev_dict\n",
    "\n",
    "\n",
    "def normalize_df(df, decision_col, mean_dict, stdev_dict):\n",
    "    for c in df.columns:\n",
    "        if c != decision_col:\n",
    "            if c in stdev_dict and stdev_dict[c] != 0:\n",
    "                df[c] = (df[c] - mean_dict[c]) / stdev_dict[c]\n",
    "            else:\n",
    "                df[c] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a31ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default_rate-group_1_a',\n",
       " 'default_rate-group_2_a',\n",
       " 'acceptance_rate-group_1_a',\n",
       " 'acceptance_rate-group_2_a',\n",
       " 'average_credit_score-group_2_a',\n",
       " 'average_credit_score-group_1_a',\n",
       " 'applicant_credit_group_a',\n",
       " 'applicant_group_membership_a',\n",
       " 'agent_action_a',\n",
       " 'default_rate-group_1_b',\n",
       " 'default_rate-group_2_b',\n",
       " 'acceptance_rate-group_1_b',\n",
       " 'acceptance_rate-group_2_b',\n",
       " 'average_credit_score-group_2_b',\n",
       " 'average_credit_score-group_1_b',\n",
       " 'applicant_credit_group_b',\n",
       " 'applicant_group_membership_b',\n",
       " 'agent_action_b']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model_features_extended = [f\"{i}_a\" for i in reward_model_features] + [f\"{i}_b\" for i in reward_model_features]\n",
    "reward_model_features_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ebe4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, name, layer_dims, out_act=None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(layer_dims) - 1):\n",
    "            self.layers.append(torch.nn.Linear(layer_dims[i], layer_dims[i + 1]))\n",
    "            if i < len(layer_dims) - 2:\n",
    "                torch.nn.init.kaiming_uniform_(\n",
    "                    self.layers[2 * i].weight, nonlinearity=\"relu\"\n",
    "                )\n",
    "                self.layers.append(torch.nn.ReLU())\n",
    "            else:\n",
    "                torch.nn.init.xavier_uniform_(self.layers[2 * i].weight)\n",
    "        if out_act == \"sigmoid\":\n",
    "            self.layers.append(torch.nn.Sigmoid())\n",
    "#         print(self.layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79938397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_accuracy(stacked_tensor, preferences):\n",
    "    softmax_stacked_tensor = F.softmax(stacked_tensor, dim=1)\n",
    "    preds_correct = torch.argmax(preferences, dim=1) == torch.argmax(softmax_stacked_tensor, dim=1)\n",
    "    accuracy = torch.mean(preds_correct.float())\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_model_new(model, test_loader, input_dim):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "#     y_pred = []\n",
    "#     y_true = []\n",
    "    accuracy_list = []\n",
    "#     with torch.no_grad():\n",
    "    with torch.inference_mode():\n",
    "        for features, y in test_loader:\n",
    "            features = features.to(device)\n",
    "            feature_last_dim = features.size(2)\n",
    "            curr_batch_size = features.size(0)\n",
    "            features_a = features[:, :input_dim, :]  \n",
    "            features_a = features_a.transpose(1, 2)\n",
    "            features_a = features_a.contiguous().view(-1, input_dim).to(device)\n",
    "            \n",
    "            features_b = features[:, input_dim:, :]\n",
    "            features_b = features_b.transpose(1, 2)\n",
    "            features_b = features_b.contiguous().view(-1, input_dim).to(device)\n",
    "            reward_A = model(features_a)\n",
    "            reward_B = model(features_b)\n",
    "            \n",
    "            sum_a = torch.sum(reward_A.view(curr_batch_size, -1), 1)\n",
    "            sum_b = torch.sum(reward_B.view(curr_batch_size, -1), 1)\n",
    "            y = F.one_hot(y.to(torch.int64), num_classes=2)\n",
    "            \n",
    "            sum_a = sum_a.unsqueeze(1)\n",
    "            sum_b = sum_b.unsqueeze(1)\n",
    "            stacked_tensor = torch.cat([sum_a, sum_b], dim=1)\n",
    "            stacked_tensor = stacked_tensor.to(torch.float32)\n",
    "            curr_accuracy = get_accuracy(stacked_tensor, y)\n",
    "            accuracy_list.append(curr_accuracy.item())\n",
    "#             tmp_y_pred = list(map(float, torch.gt(reward_B.detach().cpu().float(), reward_A.detach().cpu().float()).tolist()))\n",
    "#             y_pred += tmp_y_pred\n",
    "#             y_true += y.tolist()\n",
    "            \n",
    "    \n",
    "#     clf_rep = metrics.precision_recall_fscore_support(y_true, y_pred)\n",
    "#     cm_df = pd.DataFrame(metrics.confusion_matrix(y_true, y_pred))\n",
    "#     out_dict = {\n",
    "#                  \"precision\" :clf_rep[0].round(2),\n",
    "#                  \"recall\" : clf_rep[1].round(2),\n",
    "#                  \"f1-score\" : clf_rep[2].round(2),\n",
    "#                  \"support\" : clf_rep[3],\n",
    "#                  \"accuracy\": class_acc.round(2)\n",
    "#                 }\n",
    "    \n",
    "#     out_df = pd.DataFrame(out_dict)\n",
    "#     avg_tot = (out_df.apply(lambda x: round(x.mean(), 2) if x.name!=\"support\" else  round(x.sum(), 2)).to_frame().T)\n",
    "#     avg_tot.index = [\"avg/total\"]\n",
    "#     out_df = out_df.append(avg_tot)\n",
    "#     return out_df, cm_df\n",
    "    test_set_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    return test_set_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1388950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON EPOCH 0 Training Accuracy: 0.5017077575376885: \n",
      "ON EPOCH 1 Training Accuracy: 0.5021592336683417: \n",
      "ON EPOCH 2 Training Accuracy: 0.5012843234455167: \n",
      "ON EPOCH 3 Training Accuracy: 0.5025854721740263: \n",
      "ON EPOCH 4 Training Accuracy: 0.5058607773565168: \n",
      "ON EPOCH 5 Training Accuracy: 0.5054121053398554: \n",
      "ON EPOCH 6 Training Accuracy: 0.5038389494670695: \n",
      "ON EPOCH 7 Training Accuracy: 0.5087631236967729: \n",
      "ON EPOCH 8 Training Accuracy: 0.5058832108674935: \n",
      "ON EPOCH 9 Training Accuracy: 0.5072544645424464: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13508\\1948639478.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0msave_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     )\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Normalize test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13508\\407308091.py\u001b[0m in \u001b[0;36mtrain_reward_model\u001b[1;34m(model, input_dim, train_loader, loss_function, learning_rate, num_epochs, batch_size, save_dir)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# with train_loader as batches:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# batches.set_description(f\"Training - Epoch {epoch + 1} - Loss {round(losses[-1], 4)}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecisions\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\eleutherai\\rlhf_fairness\\rlhf-fairness\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\eleutherai\\rlhf_fairness\\rlhf-fairness\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\eleutherai\\rlhf_fairness\\rlhf-fairness\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\eleutherai\\rlhf_fairness\\rlhf-fairness\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13508\\1131278412.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "n_sample_points = 20\n",
    "\n",
    "# num_hidden_units = 100\n",
    "batch_size = 256\n",
    "learning_rate = 1E-5\n",
    "\n",
    "# reward_model_features_extended = [f\"{i}_a\" for i in reward_model_features] + [f\"{i}_b\" for i in reward_model_features]\n",
    "# Normalization\n",
    "train_mean_dict, train_stdev_dict = get_norm_dict(train_trajectories, decision_col)\n",
    "df_train_norm = normalize_df(train_trajectories, decision_col, train_mean_dict, train_stdev_dict)\n",
    "\n",
    "df_test_norm = normalize_df(test_trajectories, decision_col, train_mean_dict, train_stdev_dict)\n",
    "# test_loader = get_dataloader(df_test_norm, \n",
    "#                        reward_model_features_extended, \n",
    "#                        decision_col, \n",
    "#                        n_sample_points, \n",
    "#                        batch_size, \n",
    "#                        torch_seed=101, \n",
    "#                        )\n",
    "# Get dataloader\n",
    "train_loader, test_loader = get_dataloader(df_train_norm,\n",
    "                               df_test_norm,\n",
    "                               reward_model_features_extended, \n",
    "                               decision_col, \n",
    "                               n_sample_points, \n",
    "                               batch_size, \n",
    "                               torch_seed=101, \n",
    "                           )\n",
    "# Create model object\n",
    "model_input_dim = len(reward_model_features_extended)//2\n",
    "#     reward_model = ShallowRegressionLSTM(name = \"fair_lstm_reward_model\",\n",
    "#                                   num_sensors=model_input_dim, \n",
    "#                                   num_layers=1, \n",
    "#                                   hidden_units=num_hidden_units)\n",
    "\n",
    "model_hidden_config = [256, 256, 128, 128, 64, 64]\n",
    "reward_model = MLP(\n",
    "    name='mlp_with_paper_loss',\n",
    "    layer_dims=[model_input_dim] + model_hidden_config + [1],\n",
    "    out_act=None\n",
    ")\n",
    "# print([[model_input_dim] + model_hidden_config + [1]])\n",
    "# Training\n",
    "losses, reward_model = train_reward_model(\n",
    "        reward_model,\n",
    "        model_input_dim,\n",
    "        train_loader,\n",
    "        preference_loss_function_3,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        save_dir\n",
    "    )\n",
    "# Normalize test set\n",
    "\n",
    "# # K-Fold testing\n",
    "# report_df, cm_df = evaluate_model_new(reward_model, test_loader, model_input_dim)\n",
    "# report_history[i] = report_df\n",
    "# cm_history[i] = cm_df\n",
    "accuracy = evaluate_model_new(reward_model, test_loader, model_input_dim)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5a511ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4644, 0.5356], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4662, 0.5338], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4713, 0.5287], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4284, 0.5716], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4656, 0.5344], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4228, 0.5772], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4599, 0.5401], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4547, 0.5453], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4537, 0.5463], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4140, 0.5860], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4482, 0.5518], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4038, 0.5962], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4387, 0.5613], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4032, 0.5968], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4392, 0.5608], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3941, 0.6059], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4174, 0.5826], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4084, 0.5916], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4332, 0.5668], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4224, 0.5776], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4332, 0.5668], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4224, 0.5776], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4112, 0.5888], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4239, 0.5761], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4177, 0.5823], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4329, 0.5671], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4321, 0.5679], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4422, 0.5578], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4102, 0.5898], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4262, 0.5738], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4317, 0.5683], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4515, 0.5485], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4276, 0.5724], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4207, 0.5793], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4174, 0.5826], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4015, 0.5985], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4332, 0.5668], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4299, 0.5701], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4234, 0.5766], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4299, 0.5701], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4234, 0.5766], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4290, 0.5710], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4122, 0.5878], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4207, 0.5793], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4206, 0.5794], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4229, 0.5771], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4382, 0.5618], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4299, 0.5701], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4046, 0.5954], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4424, 0.5576], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4179, 0.5821], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4574, 0.5426], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4280, 0.5720], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4264, 0.5736], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4178, 0.5822], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4072, 0.5928], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4336, 0.5664], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4357, 0.5643], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4237, 0.5763], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4357, 0.5643], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4237, 0.5763], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4347, 0.5653], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4072, 0.5928], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4339, 0.5661], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4210, 0.5790], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4287, 0.5713], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4382, 0.5618], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4342, 0.5658], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4274, 0.5726], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4253, 0.5747], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4553, 0.5447], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4273, 0.5727], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4168, 0.5832], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3977, 0.6023], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4381, 0.5619], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4261, 0.5739], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4282, 0.5718], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4261, 0.5739], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4282, 0.5718], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4251, 0.5749], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4170, 0.5830], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4168, 0.5832], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4235, 0.5765], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4378, 0.5622], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4364, 0.5636], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4037, 0.5963], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4384, 0.5616], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4121, 0.5879], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4696, 0.5304], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4347, 0.5653], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4044, 0.5956], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4154, 0.5846], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4200, 0.5800], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4441, 0.5559], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4102, 0.5898], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4441, 0.5559], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4102, 0.5898], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4431, 0.5569], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3992, 0.6008], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4292, 0.5708], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4160, 0.5840], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4291, 0.5709], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4369, 0.5631], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4450, 0.5550], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3992, 0.6008], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4470, 0.5530], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4575, 0.5425], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4222, 0.5778], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4369, 0.5631], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4032, 0.5968], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4176, 0.5824], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4189, 0.5811], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4091, 0.5909], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4091, 0.5909], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4453, 0.5547], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3980, 0.6020], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4303, 0.5697], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4119, 0.5881], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4300, 0.5700], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4313, 0.5687], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3906, 0.6094], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4510, 0.5490], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4260, 0.5740], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4369, 0.5631], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4032, 0.5968], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4176, 0.5824], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4189, 0.5811], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4091, 0.5909], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4091, 0.5909], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4453, 0.5547], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3980, 0.6020], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4303, 0.5697], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4119, 0.5881], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4294, 0.5706], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4298, 0.5702], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4453, 0.5547], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3877, 0.6123], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4579, 0.5421], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4110, 0.5890], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4515, 0.5485], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4234, 0.5766], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4375, 0.5625], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4007, 0.5993], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4181, 0.5819], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4163, 0.5837], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4468, 0.5532], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4065, 0.5935], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4468, 0.5532], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4065, 0.5935], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4459, 0.5541], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3955, 0.6045], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4320, 0.5680], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4146, 0.5854], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4266, 0.5734], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4355, 0.5645], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4425, 0.5575], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3925, 0.6075], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4520, 0.5480], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4115, 0.5885], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4555, 0.5445], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4240, 0.5760], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4064, 0.5936], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4196, 0.5804], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4484, 0.5516], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4484, 0.5516], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4474, 0.5526], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3966, 0.6034], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4128, 0.5872], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4367, 0.5633], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4334, 0.5666], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4489, 0.5511], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3997, 0.6003], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4419, 0.5581], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4162, 0.5838], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4539, 0.5461], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4209, 0.5791], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4310, 0.5690], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4070, 0.5930], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4144, 0.5856], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4004, 0.5996], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4393, 0.5607], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3908, 0.6092], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4393, 0.5607], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3908, 0.6092], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4383, 0.5617], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3800, 0.6200], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4245, 0.5755], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3911, 0.6089], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4182, 0.5818], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4327, 0.5673], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3872, 0.6128], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4309, 0.5691], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.3980, 0.6020], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4538, 0.5462], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4043, 0.5957], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4174, 0.5826], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4084, 0.5916], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4332, 0.5668], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4224, 0.5776], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4332, 0.5668], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4224, 0.5776], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4112, 0.5888], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4239, 0.5761], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4177, 0.5823], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4329, 0.5671], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4317, 0.5683], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4407, 0.5593], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4098, 0.5902], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4247, 0.5753], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4290, 0.5710], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4553, 0.5447], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4273, 0.5727], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4168, 0.5832], device='cuda:0', grad_fn=<SliceBackward0>) tensor([1, 0], device='cuda:0')\n",
      "tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.3977, 0.6023], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4381, 0.5619], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4261, 0.5739], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4282, 0.5718], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4261, 0.5739], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4282, 0.5718], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4251, 0.5749], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4170, 0.5830], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4168, 0.5832], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4235, 0.5765], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4258, 0.5742], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4435, 0.5565], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4276, 0.5724], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n",
      "tensor([0.4295, 0.5705], device='cuda:0', grad_fn=<SliceBackward0>) tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def test_one_sample(model, test_loader, input_dim):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    features, y = next(iter(test_loader))\n",
    "    features = features.to(device)\n",
    "    feature_last_dim = features.size(2)\n",
    "    curr_batch_size = features.size(0)\n",
    "    features_a = features[:, :input_dim, :]\n",
    "    features_a = features_a.transpose(1, 2)\n",
    "    features_a = features_a.contiguous().view(-1, input_dim).to(device)\n",
    "\n",
    "    features_b = features[:, input_dim:, :]\n",
    "    features_b = features_b.transpose(1, 2)\n",
    "    features_b = features_b.contiguous().view(-1, input_dim).to(device)\n",
    "    \n",
    "    reward_A = model(features_a)\n",
    "    reward_B = model(features_b)\n",
    "\n",
    "    sum_a = torch.sum(reward_A.view(curr_batch_size, -1), 1)\n",
    "    sum_b = torch.sum(reward_B.view(curr_batch_size, -1), 1)\n",
    "    y = F.one_hot(y.to(torch.int64), num_classes=2)\n",
    "\n",
    "    sum_a = sum_a.unsqueeze(1)\n",
    "    sum_b = sum_b.unsqueeze(1)\n",
    "    stacked_tensor = torch.cat([sum_a, sum_b], dim=1)\n",
    "    stacked_tensor = stacked_tensor.to(torch.float32)\n",
    "    softmax_stacked_tensor = F.softmax(stacked_tensor, dim=1)\n",
    "    \n",
    "    for i in range(256):\n",
    "        print(softmax_stacked_tensor[i,:], y[i])\n",
    "\n",
    "test_one_sample(reward_model, test_loader, model_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3424289-cefd-4f05-af66-3b903fb0c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9b0a590e-5756-4789-a137-4f68f05bba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training loss of reward modelling\", size=18)\n",
    "plt.xlabel(\"Step\", size=18)\n",
    "plt.ylabel(\"Loss\", size=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "71adcfd8-0785-409b-931f-6065b51fe389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg/total</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  recall  f1-score  support  accuracy\n",
       "0               0.32    0.46      0.38   1060.0      0.45\n",
       "1               0.77    0.65      0.70   2920.0      0.58\n",
       "avg/total       0.55    0.56      0.54   3980.0      0.52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in report_history.items():\n",
    "    print(k)\n",
    "    display(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6902ba4f-b6ce-4ffb-bb5c-21712a805d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   483   577\n",
       "1  1020  1900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in cm_history.items():\n",
    "    print(k)\n",
    "    display(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e621e-d0f0-40bc-ae67-721841f66298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07497c9a-49aa-4dc8-9531-361ad9eac055",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9192\\3495597210.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreferences_df_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreferences_df_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreferences_df_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreferences_df_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_action_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreward_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreward_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_hidden_config\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_act\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_index' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = preferences_df_filtered[preferences_df_filtered.index.isin(train_index)]\n",
    "test_df = preferences_df_filtered[preferences_df_filtered.index.isin(test_index)]\n",
    "# Training\n",
    "features, decisions = train_df[state_action_features].to_numpy(), train_df[target].to_numpy()\n",
    "reward_model = MLP(name=reward_model_name, layer_dims=[features.shape[1]+1] + model_hidden_config + [1], out_act=None)\n",
    "losses = train_reward_model(\n",
    "    reward_model,\n",
    "    features,\n",
    "    decisions,\n",
    "    loss_function=preference_loss_function,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=256,\n",
    "    save_dir=save_dir)\n",
    "\n",
    "# K-Fold testing\n",
    "test_features, test_decisions = test_df[state_action_features].to_numpy(), test_df[target].to_numpy()\n",
    "predictions, metrics_report = evaluate_model(reward_model, test_features, test_decisions)\n",
    "metrics_report_history[i] = metrics_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ad9ce-919f-4c23-ad0c-d2cbeb66ab1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7bd9d19-7dcf-4074-8d06-d3a0a8a5e956",
   "metadata": {},
   "source": [
    "***\n",
    "### End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
